{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b283b030-2846-4f59-a730-e0dbe6fed677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c524e9bd-2a31-47b5-939d-f67450bc3fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11996bf6-a533-4b8a-9f21-0b81f54e58f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# On Windows platform, the torch.distributed package only\n",
    "# supports Gloo backend, FileStore and TcpStore.\n",
    "# For FileStore, set init_method parameter in init_process_group\n",
    "# to a local file. Example as follow:\n",
    "# init_method=\"file:///f:/libtmp/some_file\"\n",
    "# dist.init_process_group(\n",
    "#    \"gloo\",\n",
    "#    rank=rank,\n",
    "#    init_method=init_method,\n",
    "#    world_size=world_size)\n",
    "# For TcpStore, same way as on Linux.\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63a84cb-1362-43c4-94e2-73bb7b221852",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyModel, self).__init__()\n",
    "        self.net1 = nn.Linear(10, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.net2 = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net2(self.relu(self.net1(x)))\n",
    "\n",
    "\n",
    "def demo_basic(rank, world_size):\n",
    "    print(f\"Running basic DDP example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    # create model and move it to GPU with id rank\n",
    "    model = ToyModel().to(rank)\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = ddp_model(torch.randn(20, 10))\n",
    "    labels = torch.randn(20, 5).to(rank)\n",
    "    loss_fn(outputs, labels).backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "\n",
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61cd074-c64b-4c16-8a14-69a6f531aedd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-596d9b53c619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdemo_basic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-c786ef8f0fb3>\u001b[0m in \u001b[0;36mrun_demo\u001b[0;34m(demo_fn, world_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m              \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m              \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m              join=True)\n\u001b[0m",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    228\u001b[0m                ' torch.multiprocessing.start_processes(...)' % start_method)\n\u001b[1;32m    229\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0merror_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0merror_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m                 )\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "run_demo(demo_basic, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a25ba8-209d-44a3-a6e0-201924fd66ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78498fed-4867-4881-bf73-201513ea48c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9153d4-9959-4a86-8a13-15c43fd60d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d996f5f-a208-4fb5-9e51-da3b70fa18ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74756f92-2e94-47c6-ade7-95b3bb26a7e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-3f59a93a5a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToyModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# net = torch.nn.parallel.DistributedDataParallel(net, device_ids=['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/nn/parallel/distributed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, device_ids, output_device, dim, broadcast_buffers, process_group, bucket_cap_mb, find_unused_parameters, check_reduction, gradient_as_bucket_view)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprocess_group\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    356\u001b[0m     \"\"\"\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         raise RuntimeError(\"Default process group has not been initialized, \"\n\u001b[0m\u001b[1;32m    359\u001b[0m                            \"please make sure to call init_process_group.\")\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mGroupMember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "net = ToyModel()\n",
    "# net = torch.nn.parallel.DistributedDataParallel(net, device_ids=['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3'])\n",
    "net = torch.nn.parallel.DistributedDataParallel(net, device_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0679123d-18cb-46f9-9f15-c01b4224467b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.12 s, sys: 271 ms, total: 1.39 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = net(torch.randn(10000000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddb8a0-2365-40ff-aa9e-31838ad1cae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8102e13-6511-4b1a-9970-ea6e48e419d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e83e22-8a56-450d-9199-e9f4fab29956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c201cc0b-af94-4c36-9ec2-5d8d1e08b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dad0d8d5-f186-4e69-946c-9f78cc8f9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-n', '--nodes', default=1, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('-g', '--gpus', default=1, type=int,\n",
    "                    help='number of gpus per node')\n",
    "parser.add_argument('-nr', '--nr', default=0, type=int,\n",
    "                    help='ranking within the nodes')\n",
    "parser.add_argument('--epochs', default=2, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "args = parser.parse_args(args='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5692c5aa-bf60-45cb-882e-923b735cc549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(epochs=2, gpus=1, nodes=1, nr=0, world_size=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import torch.multiprocessing as mp\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-n', '--nodes', default=1, type=int, metavar='N',\n",
    "                        help='number of data loading workers (default: 4)')\n",
    "    parser.add_argument('-g', '--gpus', default=1, type=int,\n",
    "                        help='number of gpus per node')\n",
    "    parser.add_argument('-nr', '--nr', default=0, type=int,\n",
    "                        help='ranking within the nodes')\n",
    "    parser.add_argument('--epochs', default=2, type=int, metavar='N',\n",
    "                        help='number of total epochs to run')\n",
    "    args = parser.parse_args('')\n",
    "    args.world_size = args.gpus * args.nodes\n",
    "    print(args)\n",
    "    os.environ['MASTER_ADDR'] = '10.57.23.164'\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '8888'\n",
    "    mp.spawn(train, nprocs=args.gpus, args=(args,), join=False)\n",
    "\n",
    "def train(gpu, args):\n",
    "    print(f'training on gpu {gpu}')\n",
    "    rank = args.nr * args.gpus + gpu\n",
    "    dist.init_process_group(backend='nccl', init_method='env://', world_size=args.world_size, rank=rank)\n",
    "    torch.manual_seed(0)\n",
    "    model = ConvNet()\n",
    "    torch.cuda.set_device(gpu)\n",
    "    model.cuda(gpu)\n",
    "    batch_size = 100\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 1e-4)\n",
    "    # Wrap the model\n",
    "    model = nn.parallel.DistributedDataParallel(model, device_ids=[gpu])\n",
    "    # Data loading code\n",
    "\n",
    "    transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    #     torchvision.transforms.Resize((h, w), ), \n",
    "    #     Rearrange('c (nph psh) (npw psw) -> (nph npw) (psh psw c)', nph=8, npw=8),\n",
    "    ])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='~/datasets/cifar10/', \n",
    "                                            train=True, \n",
    "                                            download=True, \n",
    "                                            transform=transform)\n",
    "    \n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset,\n",
    "                                                                    num_replicas=args.world_size,\n",
    "                                                                    rank=rank)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=False,\n",
    "                                               num_workers=0,\n",
    "                                               pin_memory=True,\n",
    "                                               sampler=train_sampler)\n",
    "\n",
    "    start = datetime.now()\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(args.epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            labels = labels.cuda(non_blocking=True)\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 100 == 0 and gpu == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, args.epochs, i + 1, total_step,\n",
    "                                                                         loss.item()))\n",
    "    if gpu == 0:\n",
    "        print(\"Training complete in: \" + str(datetime.now() - start))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c640146d-4b22-47af-9640-5923f55a960b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7ce09-035e-4e50-ab18-4f6870709655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29626dc5-8975-48b8-838c-48241e27aebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2988245d-980a-48a6-bb2b-b2dd8afbe986",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProcessExitedException",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExitedException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7daaabb9a976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhello\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    228\u001b[0m                ' torch.multiprocessing.start_processes(...)' % start_method)\n\u001b[1;32m    229\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlp-shaker/env/lib64/python3.6/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    142\u001b[0m                     \u001b[0merror_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0merror_pid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfailed_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                     \u001b[0mexit_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m                 )\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProcessExitedException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "def hello():\n",
    "    print('hello')\n",
    "mp.spawn(hello, nprocs=1, args=(), join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20b0364-2a22-4239-a57e-b1e512e741d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ee4f8-a33b-49eb-8e48-1875838dd4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1140a9ab-2d72-4e31-8a89-3019c40a350b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0682c6f7-0b91-4831-906f-3c74b12d74a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5be00e-dd43-4851-88cc-0b388a5e5143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "799890c9-a983-48f4-a26e-7efce0d38535",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db1bf92-1f73-42eb-9389-de3ddb90d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7610adfa-c414-4dc9-9d28-b3dd01758a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(8*8*32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        print(out.device)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0b76c34-1930-462a-bc82-f3932287d895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating ds\n",
      "Files already downloaded and verified\n",
      "starting training\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:3\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:2\n",
      "cuda:0\n",
      "cuda:3cuda:1\n",
      "\n",
      "cuda:1cuda:2\n",
      "\n",
      "cuda:3cuda:0\n",
      "\n",
      "Epoch [1/3], Step [10/50], Loss: 2.0629\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:2\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:2cuda:0cuda:1\n",
      "cuda:3\n",
      "\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0cuda:3\n",
      "cuda:1\n",
      "cuda:2\n",
      "\n",
      "Epoch [1/3], Step [20/50], Loss: 1.9158\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:1cuda:0cuda:2\n",
      "\n",
      "\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0cuda:3\n",
      "cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:2\n",
      "cuda:0cuda:3\n",
      "\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:3\n",
      "cuda:1\n",
      "cuda:2cuda:0\n",
      "cuda:1\n",
      "\n",
      "cuda:3\n",
      "Epoch [1/3], Step [30/50], Loss: 1.8123\n",
      "cuda:0\n",
      "cuda:1cuda:2\n",
      "\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "cuda:3\n",
      "\n",
      "cuda:1\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:0cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2cuda:3\n",
      "\n",
      "cuda:1\n",
      "\n",
      "cuda:2cuda:0\n",
      "\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1cuda:3cuda:2\n",
      "\n",
      "\n",
      "cuda:2cuda:0\n",
      "\n",
      "cuda:1cuda:3\n",
      "\n",
      "Epoch [1/3], Step [40/50], Loss: 1.7978\n",
      "cuda:0cuda:3\n",
      "cuda:1\n",
      "cuda:2\n",
      "\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:3\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2cuda:3\n",
      "\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:2\n",
      "cuda:3\n",
      "Epoch [1/3], Step [50/50], Loss: 1.6714\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:2\n",
      "cuda:0cuda:2\n",
      "cuda:3\n",
      "\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:1cuda:0\n",
      "cuda:3\n",
      "cuda:2\n",
      "\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:3\n",
      "cuda:1\n",
      "cuda:0cuda:1cuda:2cuda:3\n",
      "\n",
      "\n",
      "\n",
      "cuda:2cuda:0\n",
      "cuda:3cuda:1\n",
      "\n",
      "\n",
      "Epoch [2/3], Step [10/50], Loss: 1.6263\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:3cuda:2\n",
      "\n",
      "cuda:1\n",
      "\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:0cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1cuda:3\n",
      "cuda:2\n",
      "\n",
      "cuda:0\n",
      "cuda:3\n",
      "cuda:2cuda:1\n",
      "\n",
      "cuda:2\n",
      "cuda:0\n",
      "cuda:3cuda:1\n",
      "\n",
      "Epoch [2/3], Step [20/50], Loss: 1.6111\n",
      "cuda:0\n",
      "cuda:1cuda:2\n",
      "\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:3cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:1cuda:0\n",
      "\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:3cuda:1\n",
      "\n",
      "cuda:0cuda:1\n",
      "cuda:2\n",
      "\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:3cuda:1\n",
      "\n",
      "Epoch [2/3], Step [30/50], Loss: 1.6149\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:2cuda:0\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:1\n",
      "cuda:2\n",
      "\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:1\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:3cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:1cuda:0\n",
      "\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0cuda:3\n",
      "cuda:2\n",
      "\n",
      "cuda:1\n",
      "Epoch [2/3], Step [40/50], Loss: 1.5797\n",
      "cuda:2\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:3cuda:2\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:3cuda:1\n",
      "\n",
      "cuda:2cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:0cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:2\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:3cuda:1\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:3cuda:2\n",
      "\n",
      "Epoch [2/3], Step [50/50], Loss: 1.5755\n",
      "cuda:1cuda:0cuda:2\n",
      "\n",
      "\n",
      "cuda:3\n",
      "cuda:0cuda:1\n",
      "cuda:3\n",
      "cuda:2\n",
      "\n",
      "cuda:3cuda:1\n",
      "\n",
      "cuda:2cuda:0\n",
      "\n",
      "cuda:2cuda:0\n",
      "\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "Epoch [3/3], Step [10/50], Loss: 1.5376\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:3cuda:1\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2cuda:3\n",
      "cuda:1\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "Epoch [3/3], Step [20/50], Loss: 1.5303\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:0cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:3cuda:2\n",
      "\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:3cuda:2\n",
      "\n",
      "cuda:0cuda:2cuda:1\n",
      "\n",
      "cuda:3\n",
      "\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "Epoch [3/3], Step [30/50], Loss: 1.5024\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2\n",
      "\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:2cuda:0\n",
      "cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:1\n",
      "\n",
      "cuda:2\n",
      "cuda:3\n",
      "Epoch [3/3], Step [40/50], Loss: 1.4382\n",
      "cuda:0cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:2\n",
      "cuda:3\n",
      "cuda:2cuda:0\n",
      "cuda:1\n",
      "cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:2\n",
      "cuda:2\n",
      "cuda:0cuda:3\n",
      "\n",
      "cuda:1\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1cuda:3\n",
      "\n",
      "cuda:0\n",
      "cuda:2\n",
      "cuda:1\n",
      "cuda:3\n",
      "cuda:0cuda:2cuda:1\n",
      "\n",
      "\n",
      "cuda:3\n",
      "Epoch [3/3], Step [50/50], Loss: 1.4682\n",
      "Training complete in: 34.68215990066528\n"
     ]
    }
   ],
   "source": [
    "def train(net):\n",
    "    torch.manual_seed(0)\n",
    "    batch_size = 1000\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(net.parameters(), 1e-2)\n",
    "    # Data loading code\n",
    "    transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    #     torchvision.transforms.Resize((h, w), ), \n",
    "    #     Rearrange('c (nph psh) (npw psw) -> (nph npw) (psh psw c)', nph=8, npw=8),\n",
    "    ])\n",
    "    print('creating ds')\n",
    "    train_dataset = torchvision.datasets.CIFAR10(root='~/datasets/cifar10/', \n",
    "                                            train=True, \n",
    "                                            download=True, \n",
    "                                            transform=transform)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True,)\n",
    "\n",
    "    start = time.time()\n",
    "    total_step = len(train_loader)\n",
    "    print('starting training')\n",
    "    n_epochs = 3\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to('cuda:0')\n",
    "            labels = labels.to('cuda:0')\n",
    "            # Forward pass\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch + 1, n_epochs, i + 1, total_step,\n",
    "                                                                         loss.item()))\n",
    "\n",
    "    print(\"Training complete in: \" + str(time.time() - start))\n",
    "    \n",
    "net = ConvNet().to('cuda:0')\n",
    "net = nn.DataParallel(net, [0, 1, 2, 3])\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbcb1a6-63d5-45e1-90b8-1a77557d1a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f2364a-0715-4bb7-a491-69543feee84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
